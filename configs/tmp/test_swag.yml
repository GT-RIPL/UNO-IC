id: rgbd_BayesianSegnet_SoftmaxMult
model:
    arch: segnet_mcdo
models:
    rgb:
        in_channels: 3
        start_layer: down1
        end_layer: up1
        reduction: 1.0
        mcdo_passes: 6 # Number of Passes
        dropoutP: 0.5 # Dropout Probability
        resume: /home/wcheung8/Desktop/pytorch-semseg/models/rgb_BayesianSegnet_0.5_T000/rgb_segnet_mcdo_airsim_best_model.pkl
fusion: None #{None,SoftmaxMultiply}
recal: None #{None,afterMCDO,beforeMCDO}
recalibrator: None #{Histogram,Polynomial_X}
bins: 20
data:
    dataset: airsim
    train_split: train
    train_subsplit: ['async_fog_000_clear']
    train_reduction: 0.1   
    recal_split: recal
    recal_subsplit: ['async_fog_000_clear']
    recal_reduction: 0.1
    val_split: val
    val_subsplit: [
                   'async_fog_000_clear',
                   'async_fog_050_clear',
                   'async_fog_100_clear',
                  ]    
    val_reduction: 0.1
    img_rows: 512
    img_cols: 512
    path: datasets/airsim_data_async #../../ros/data/airsim_03-30-2019/airsim_data_async
    noisy_type: None 
training:
    train_iters: 100500
    batch_size: 2
    val_interval: 500 #5000
    n_workers: 8
    print_interval: 50
    png_frames: 50 #5000
    optimizer:
        name: 'adam'
        lr: 1.0e-5
    loss:
        name: 'cross_entropy'
        size_average: False
    lr_schedule:
    resume: None
swa:
    start: 50 # SWA start epoch number (default: 100000)
    lr: 0.02 # SWA LR (default: 0.02)
    c_iterations: 50 # SWA model collection frequency/cycle length in epochs (default: 1)
    resume: None # checkpoint to restore SWA from (default: None)